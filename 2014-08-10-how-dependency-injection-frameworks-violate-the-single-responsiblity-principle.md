Dependency injection frameworks, people seem to love them or hate them. Proponents tout that if you don't use them you're not inverting dependencies in an ideal way, and your code wont be as flexible and testable as it could be. Those who are weary of them can feel they are wasting time hunting down implementations of far flung, cryptic and ambiguous abstractions in unfamiliar code. It can seem that something simple has been made unnecessarily more complex.

At EMIS we have our own system called Composition. I intentionally don't call it a framework because there are only two public types. One has two methods and the other is an empty attribute. People new to the company often ask why we have guidance to use it with pure/manual dependency inversion instead of a "proper" injection framework and why doesn't it have a particular feature (e.g. auto-wiring, lifetime management). This prompts discussion about the inversion principle and what they wanted to achieve that lead them to feel that they needed a feature from an injection framework. Features are added to injection frameworks to compensative for others (e.g. lifetime management because auto-wiring instantiates, auto registration because a container isn't modular). Usually the developer just needs to invert a dependency via an abstraction, but the injection framework encourages them to add unnecessary complexity, obscurity and ambiguity. When lifetime management or implementation discovery is actually needed by the developer, these are separate concern to inverting dependencies. They often get conceptually mixed up by the developer with inversion, because of the number of features added to most injection frameworks.

Depending on abstractions will help make a class testable, but the perception by many developers that this alone will also structure the entire system in beneficial way. Although the principle applies at all scales, the needs of individual classes and high level components are different. Depending on an interface, defined with the implementation, that matches its public members, is just indirection in relation to structure. It doesn't make the system modular, this is evident in the interest people show in approaches like ports and adapters.

What differentiates injection frameworks from pure/manual dependency inversion is auto-wiring. This allows many types to be easily brought together via inverted abstractions on multiple classes, the implementations are "injected" everywhere down into where they are requested. From the perspective of the class this can appear ideal, a class depends on a limited number of abstractions and the implementations needed to satisfy them are the injection frameworks responsibility. For this to work the implementations must be aware of the abstractions (e.g. interfaces) and so (as described above) this is just indirection and not modularity. In a small system, a single container is often used and the lack of modularity isn't evident or even a problem. In a large system, with many developers, the lack of modularity from a single container or auto registration being used becomes counter productive. To counteract this multiple containers can be used, isolated to sub-systems. The more containers there are, the smaller they are and auto-wiring becomes less beneficial.

Deep within a system the most succinct, modular and flexible dependency is that of a function/data. By not using an injection framework your able to take full advantage of the language and use features like delegates to represent abstractions. This avoids making the code dependent on an abstraction defined elsewhere and for multiple purposes e.g. the interfaces described above. This flattens what could have needlessly become a hierarchy of dependencies. You don't need to write in a functional style to do this, it can be a method on class that has state. You can still take advantage of structure/object-orientation and when needed bring together commonality in dependencies. 

The problems inherent to auto-wiring and the alternative techniques to flattening the dependency structure described above, work from both sides to marginalise injection frameworks. 

The EMIS Composition system mentioned earlier has one responsibility, dynamically bring together components into a modular system in a type safe way. This might be user-facing components that don't need each other to function individually or framework components with many plug-ins. Registering of implementations happens on build and its normally called via static versions of those two methods. The reason what we use is so straightforward and we wrote our own is it's not dependency injection, its even more fundamental than a service locator. Its a commonly held belief that service locators are an anti-pattern and I'd agree with that ([ploeh - Service Locator is an Anti-Pattern](http://blog.ploeh.dk/2010/02/03/ServiceLocatorisanAnti-Pattern/)). Where a service locator allows tests to be written for code with dependencies hidden inside, our system does not. This means the developer must make dependencies clear by inverting them (e.g. via the constructors). 

In my experience combining independent pure/manual inversion of dependencies with our Composition system is better because its explicit, each have a single responsibility. People think more clearly about the clarity of dependencies and modularity without the distraction of injection frameworks. They're encouraged to use dependency inversion everywhere to help encapsulate and test the code, and only when necessary (much less frequently) doing dynamic resolution separately to decouple at a module/feature level. Only when there is the need (e.g. plugins) are both used in conjunction.